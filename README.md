# GUSCrawler

**GUSCrawler** is a high-performance, multi-agent asynchronous web crawler built in Python.  
Designed for speed, efficiency, and massive scalability â€” no GPU required.

---

## ğŸš€ Features

- Multi-agent asynchronous crawling
- Smart URL deduplication
- Dynamic target discovery
- Customizable seed list
- Built-in logging and stats tracking
- Lightweight and resource-friendly

---

## ğŸ§  Tech Stack

- **Language:** Python 3.x  
- **Core:** `asyncio`, `aiohttp`, `beautifulsoup4`  
- **Logging:** `rich` or `colorama` (optional for styled output)

---

## ğŸ“ Structure

gus_crawler/ <br>
â”‚ <br>
â”œâ”€â”€ main.py # entry point <br>
â”œâ”€â”€ banner.py # GUS banner display <br>
â”œâ”€â”€ agents/ # async crawling agents <br>
â”œâ”€â”€ utils/ # helper modules (parser, URL cleaner, etc.) <br>
â””â”€â”€ README.md


---

## âš™ï¸ Usage

```bash
python main.py --seeds seeds.txt --max-depth 3 --save output.txt
```
Or,
```bash
python main.py
```

## ğŸ§ª Example Output
- [âœ…] Total URLs saved (including discovered links): 3383


  ## ğŸ License

GNU General Public License v3.0 (GPL-3.0) Â© 2025 Morse Dev  
Free to use, modify, and distribute under the terms of the GPL-3.0.

